
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>EpiDiff: Enhancing Multi-View Synthesis via Localized Epipolar-Constrained Diffusion</title>
    <!-- Bootstrap -->
    <link href="css/bootstrap-4.4.1.css" rel="stylesheet">
    <link href="css/custom.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    <!-- <link href='http://fonts.googleapis.com/css?family=Open+Sans:400italic,700italic,800italic,400,700,800' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="css/project.css" media="screen" />
    <link rel="stylesheet" type="text/css" media="screen" href="css/iconize.css" />
    <script src="js/google-code-prettify/prettify.js"></script> -->
  </head>

  <!-- cover -->
  <section>
    <div class="jumbotron text-center mt-0">
      <div class="container">
        <div class="row">
          <div class="col-12">
            <h2>EpiDiff: Enhancing Multi-View Synthesis via Localized <br> Epipolar-Constrained Diffusion</h2>
            <h4 style="color:#5a6268;">CVPR 2024</h4>
            <hr>
            <h6 style="line-height: 26px;">
              <a href="https://github.com/huanngzh" target="_blank">Zehuan Huang</a><sup>1*</sup>,
              <a href="https://github.com/Costwen" target="_blank">Hao Wen</a><sup>1*</sup>,
              <a href="https://jtdong.com" target="_blank">Junting Dong</a><sup>2*</sup>,
              <a href="https://wyhsirius.github.io" target="_blank">Yaohui Wang</a><sup>2</sup>,
              <a href="https://scholar.google.com/citations?user=a7AMvgkAAAAJ" target="_blank">Yangguang Li</a><sup>3</sup>,
              <a href="https://scholar.google.com/citations?user=3fWSC8YAAAAJ" target="_blank">Xinyuan Chen</a><sup>2</sup>,<br>
              <a href="https://scholar.google.com/citations?user=50194vkAAAAJ" target="_blank">Yan-Pei Cao</a><sup>3</sup>,
              <a href="https://scholar.google.com/citations?user=Dqjnn0gAAAAJ" target="_blank">Ding Liang</a><sup>3</sup>,
              <a href="https://scholar.google.com/citations?user=gFtI-8QAAAAJ" target="_blank">Yu Qiao</a><sup>2</sup>,
              <a href="https://daibo.info" target="_blank">Bo Dai</a><sup>2✉</sup>,
              <a href="https://scholar.google.com/citations?user=_8lB7xcAAAAJ" target="_blank">Lu Sheng</a><sup>1</sup></h6>
          <p style="line-height: 26px;">
              <sup>1</sup>Beihang University &nbsp;&nbsp;
              <sup>2</sup>Shanghai AI Laboratory &nbsp;&nbsp;
              <sup>3</sup>VAST <br>
              <sup>*</sup>Equal Contribution &nbsp;&nbsp;
              <sup>✉</sup>Corresponding Author
          </p>

          <div class="row justify-content-center">
            <div class="column">
                <p class="mb-5"><a class="btn btn-large btn-light" href="https://arxiv.org/abs/2312.06725" role="button"  target="_blank">
                  <i class="fa fa-file"></i> Paper </a> </p>
            </div>
            <div class="column">
                <p class="mb-5"><a class="btn btn-large btn-light" href="https://github.com/huanngzh/EpiDiff" role="button"  target="_blank">
                  <i class="fa fa-github-alt"></i> Code </a> </p>
            </div>
            <div class="column">
                <p class="mb-5"><a class="btn btn-large btn-light" href="https://huggingface.co/huanngzh/EpiDiff" role="button"  target="_blank">
                  <i class="fa fa-database"></i> Model </a> </p>
            </div>
            <!-- 
            <div class="column">
                <p class="mb-5"><a class="btn btn-large btn-light" href="" role="button"  target="_blank">
                  <i class="fa fa-desktop"></i> Live Demo </a> </p>
            </div> -->
          </div>
          </div>
        </div>
      </div>
    </div>
  </section>


  <!-- abstract -->
  <section>
    <div class="container">
        <div class="warp-container">
          <div class="row">
            <div class="col-12 text-center">
              <h3>Abstract</h3>
                <hr style="margin-top:0px">
                <h6 style="color:#8899a5" class="text-left"> EpiDiff only takes 12 seconds to generate 16 multiview-consistent and high-quality images. Instead of limited to fixed views, EpiDiff can generate relatively arbitrary multiviews. The generated images can be used to recover 3D shapes by NeuS or InstantNeuS. </h6>
    
                  <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                      <source src="video/teaser.mp4" type="video/mp4">
                  </video>
    
                  <br>
    
              <p class="text-left">
                Generating multiview images from a single view facilitates the rapid generation of a 3D mesh conditioned on a single image. Recent methods that introduce 3D global representation into diffusion models have shown the potential to generate consistent multiviews, but they have reduced generation speed and face challenges in maintaining generalizability and quality. To address this issue, we propose EpiDiff, a localized interactive multiview diffusion model. At the core of the proposed approach is to insert a lightweight epipolar attention block into the frozen diffusion model, leveraging epipolar constraints to enable cross-view interaction among feature maps of neighboring views. The newly initialized 3D modeling module preserves the original feature distribution of the diffusion model, exhibiting compatibility with a variety of base diffusion models. Experiments show that EpiDiff generates 16 multiview images in just 12 seconds, and it surpasses previous methods in quality evaluation metrics, including PSNR, SSIM and LPIPS. Additionally, EpiDiff can generate a more diverse distribution of views, improving the reconstruction quality from generated multiviews.
              </p>
    
              <img src="assets/pipeline.png" alt="Overview" width="100%">
    
            <p class="text-left">
              Pipeline of EpiDiff. Our method designs a module for modeling consistency, which is inserted into the base diffusion model.
            </p>
            </div>
          </div>
        </div>
    </div>
  </section>
  <br>

  <section>
    <div class="container">
        <div class="warp-container">
          <div class="row">
            <div class="col-12 text-center">
                <h2>Epipolar-constrained Attention Block (ECA Block)</h2>
                <hr style="margin-top:0px">
                <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                    <source src="video/eca_block.mp4" type="video/mp4">
                </video>
              <p class="text-left">
                For the target view, we use cross attention to aggregate epipolar line features from nearby views, and self attention to fuse spatial points into pixel features.
              </p>
            </div>
        </div>
        </div>
    </div>
  </section>
  <br>

  <section>
    <div class="container">
        <div class="warp-container">
          <div class="row">
            <div class="col-12 text-center">
                <h2>Camera settings in training and evaluation</h2>
                <hr style="margin-top:0px">
                <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                    <source src="video/camera_settings.mp4" type="video/mp4">
                </video>
              <p class="text-left">
                During training, we randomly sample 16 views out of the 96 rendered views. For evaluation, we select 16 views in two different settings: one with a fixed elevation of 30°, and another with uniformly distributed elevations.
              </p>
            </div>
        </div>
        </div>
    </div>
  </section>
  <br>

  <section>
    <div class="container">
        <div class="warp-container">
          <div class="row">
            <div class="col-12 text-center">
                <h2>Results on the Google Scanned Object dataset</h2>
                <hr style="margin-top:0px">
                <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                    <source src="video/gso_comparison.mp4" type="video/mp4">
                </video>
              <p class="text-left">
                
              </p>
            </div>
        </div>
        </div>
    </div>
  </section>
  <br>

  <section>
    <div class="container">
        <div class="warp-container">
          <div class="row">
            <div class="col-12 text-center">
                <h2>Fix elevation 30° VS uniform elevations</h2>
                <hr style="margin-top:0px">
                <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                    <source src="video/abla_elevations.mp4" type="video/mp4">
                </video>
              <p class="text-left">
                Using uniformly distributed multiviews generated from the input image can produce better 3D shapes.
              </p>
            </div>
        </div>
        </div>
    </div>
  </section>
  <br>

  <section>
    <div class="container">
        <div class="warp-container">
          <div class="row">
            <div class="col-12 text-center">
                <h2>More results</h2>
                <hr style="margin-top:0px">
                <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                    <source src="video/more_results.mp4" type="video/mp4">
                </video>
                <p class="text-left">
                  Test images are from the GSO dataset, the Internet or generated by Stable Diffusion.
                </p>
            </div>
          </div>
        </div>
    </div>
  </section>
  <br>

  <!-- citing -->
  <div class="container">
    <div class="warp-container">
    <div class="row">
      <div class="col-12">
          <h3>Citation</h3>
          <hr style="margin-top:0px">
              <pre style="background-color: #e9eeef;padding: 1.25em 1.5em">
<code>@misc{huang2023epidiff,
  title={EpiDiff: Enhancing Multi-View Synthesis via Localized Epipolar-Constrained Diffusion},
  author={Zehuan Huang and Hao Wen and Junting Dong and Yaohui Wang and Yangguang Li and Xinyuan Chen and Yan-Pei Cao and Ding Liang and Yu Qiao and Bo Dai and Lu Sheng},
  journal={arXiv preprint arXiv:2312.06725},
  year={2023}
}</code></pre>
          <hr>
      </div>
    </div>
  </div>
  </div>

  <footer class="text-center" style="margin-bottom:10px">
    This website is adapted from <a href="https://liuyuan-pal.github.io/SyncDreamer/" target="_blank">SyncDreamer</a>.
  </footer>

</body>
</html>
